{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load seismic event file with relative times and filenames\n",
    "events_df = pd.read_csv('path_to_event_log.csv')\n",
    "\n",
    "# Function to check if a time falls within a cluster's time range\n",
    "def is_time_in_cluster(cluster_start, cluster_end, event_time):\n",
    "    return cluster_start <= event_time <= cluster_end\n",
    "\n",
    "# Function to process the seismic data and match clusters with events\n",
    "def process_seismic_clusters(input_folder, output_folder, event_data):\n",
    "    # Loop through all processed files in the input folder\n",
    "    for file in os.listdir(input_folder):\n",
    "        if file.endswith('.csv'):\n",
    "            input_file_path = os.path.join(input_folder, file)\n",
    "            \n",
    "            # Load the seismic data processed by Octave (contains cluster ids and relative times)\n",
    "            seismic_df = pd.read_csv(input_file_path)\n",
    "\n",
    "            # Remove rows where cluster_id is 0 (no cluster)\n",
    "            seismic_df = seismic_df[seismic_df['cluster_id'] != 0]\n",
    "            \n",
    "            # Ensure the filename matches between the event log and processed data\n",
    "            matching_events = event_data[event_data['filename'] == file]\n",
    "            \n",
    "            # Loop over the clusters in the seismic data\n",
    "            for cluster_id in seismic_df['cluster_id'].unique():\n",
    "                # Get the data corresponding to the current cluster\n",
    "                cluster_data = seismic_df[seismic_df['cluster_id'] == cluster_id]\n",
    "                \n",
    "                # Determine the start and end time of the cluster (in relative time)\n",
    "                cluster_start = cluster_data['time_rel'].min()\n",
    "                cluster_end = cluster_data['time_rel'].max()\n",
    "                \n",
    "                # Initialize the cluster label to 0 (non-quake)\n",
    "                seismic_df.loc[seismic_df['cluster_id'] == cluster_id, 'quake_cluster'] = 0\n",
    "\n",
    "                # Loop through matching events to check if they fall within the cluster's time range\n",
    "                for _, event_row in matching_events.iterrows():\n",
    "                    event_time = event_row['time_rel']\n",
    "                    \n",
    "                    if is_time_in_cluster(cluster_start, cluster_end, event_time):\n",
    "                        # If the event time falls within the cluster range, mark the cluster as a quake\n",
    "                        seismic_df.loc[seismic_df['cluster_id'] == cluster_id, 'quake_cluster'] = 1\n",
    "\n",
    "            # Save the processed data with updated quake labels to the output folder\n",
    "            output_file_path = os.path.join(output_folder, file)\n",
    "            seismic_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Paths for your input and output folders\n",
    "input_folder = 'path_to_octave_output_folder'\n",
    "output_folder = 'path_to_save_processed_files'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Call the function to process the seismic clusters and match them with event times\n",
    "process_seismic_clusters(input_folder, output_folder, events_df)\n",
    "\n",
    "print(\"Seismic clusters processed and saved to the output folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
